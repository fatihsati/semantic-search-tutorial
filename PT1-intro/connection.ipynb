{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector db Connection\n",
    "**connect to qdrant vector store with Python qdrant_client**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Before starting this tutorial please make sure you read the *installation.md* file for qdrant installation.\n",
    "\n",
    "Make sure you installed qdrant_client, to install it:\n",
    "```bash\n",
    "pip install qdrant-client\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lets create a qdrant client and connect to our Vector DB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<qdrant_client.qdrant_client.QdrantClient at 0x10594c8b0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import qdrant_client\n",
    "\n",
    "client = qdrant_client.QdrantClient(host=\"localhost\", port=6333)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have successfuly created the client.\n",
    "Now lets create the Embedding model we are going to use for representing documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 384, 'do_lower_case': False}) with Transformer model: MPNetModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "MODEL_NAME_OR_PATH = \"sentence-transformers/all-mpnet-base-v2\" # you may use any model you like\n",
    "model = SentenceTransformer(MODEL_NAME_OR_PATH)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have a qdrant client and a model to extract embeddings.\n",
    "Lets create a collection that we will store our data\n",
    "- You may give any name to *collection_name*\n",
    "- You may directly define dimension of your model's outputs. This code will only work for transformers based models\n",
    "- You may choose DOT or EUCLID as a distince value if you like to. (I suggest to use COSINE for sentence-transformer models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CollectionsResponse(collections=[CollectionDescription(name='example_collection')])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from qdrant_client.http.models import VectorParams, Distance\n",
    "\n",
    "COLLECTION_NAME = \"example_collection\"\n",
    "\n",
    "client.create_collection(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    vectors_config=VectorParams(\n",
    "        size=model.get_sentence_embedding_dimension(),\n",
    "        distance=Distance.COSINE,\n",
    "    )\n",
    ")\n",
    "\n",
    "client.get_collections()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The collection is successfuly created.\n",
    "Now lets read the data we want to index into collection\n",
    "The data that i am going to use is related with books and their title. The data is created by ChatGPT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Data Structures and Algorithms',\n",
       " 'date': '2023-08-02',\n",
       " 'author': 'Emily Johnson'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "DATA_PATH = './data.json'\n",
    "with open(DATA_PATH, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# print first item of the data\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to index data into collection, we need to do several steps:\n",
    "1. Create PointStruct for every document\n",
    "2. Extract embeddings for text data\n",
    "3. Index Points to collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=0, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from qdrant_client.http.models import PointStruct\n",
    "\n",
    "points = []\n",
    "for idx, doc in enumerate(data):\n",
    "    text = doc['title']\n",
    "    vector = model.encode(text).tolist() # encode text to vector\n",
    "    \n",
    "    points.append(PointStruct(\n",
    "        id=idx,\n",
    "        vector=vector,\n",
    "        payload=doc # you may store any data in payload\n",
    "    )) # add point to the list\n",
    "\n",
    "# upsert points to the collection. \n",
    "client.upsert(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    points=points,\n",
    "    wait=True # If you don't want to wait for the operation to complete, set wait=False\n",
    ")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collection is ready\n",
    "Now lets Search a document from the collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - 0.50849575 - {'author': 'William Smith', 'date': '2023-08-01', 'title': 'Artificial Intelligence Trends'}\n",
      "13 - 0.45802432 - {'author': 'Michael Brown', 'date': '2023-08-03', 'title': 'Machine Learning Basics'}\n"
     ]
    }
   ],
   "source": [
    "QUERY = \"AI\"\n",
    "query_vector = model.encode(QUERY).tolist()\n",
    "\n",
    "search_result = client.search(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    query_vector=query_vector,\n",
    "    limit=2 # return top 3 results.\n",
    ")\n",
    "\n",
    "for item in search_result:\n",
    "    print(f\"{item.id} - {item.score} - {item.payload}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Even the words **Artificial Intelligence** and **Machine Learning** are not in the query, the Sementic Search managed the retrieving relevant results.\n",
    "This is because Embeddings represent the meaning of the sentence, which means, sentences that are semanticly similar are closer to each other than the other sentences."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
